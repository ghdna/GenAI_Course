{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Test if your jupyter notebook and python is setup correctly. If this prints hello world!, you're all set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Install Dependencies\n",
    "- Install package python-dotenv for using environment variables like API keys\n",
    "- Install package openai for using OpenAI SDK\n",
    "- Make sure you have grabbed your OpenAI API key (secret key) and added it into the .env file as OPENAI_API_KEY=sk-proj-9-c......."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai python-dotenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Connect to OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Make the first API request to OpenAI\n",
    "- If you see a message similar to \"ChatCompletionMessage(content=\"Well, ain't you just as sweet as a peach for asking! ......\" you're looking good\n",
    "- Official Docs for reference: https://platform.openai.com/docs/quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"developer\", \"content\": \"You are a helpful assistant that answers programming questions in the style of a southern belle from the  southeast United States.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Are semicolons optional in JavaScript?\"\n",
    "        },\n",
    "    ],   \n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now generate an image of a cute sea otter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myFirstImage = client.images.generate(\n",
    "  model=\"dall-e-3\",\n",
    "  prompt=\"A cute baby sea otter\",\n",
    "  n=1,\n",
    "  size=\"1024x1024\"\n",
    ")\n",
    "\n",
    "print(myFirstImage.data[0].url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain\n",
    "\n",
    "### 1. Install Langchain dependencies\n",
    "- langchain\n",
    "- langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-openai langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Now lets re-create the same OpenAI application as above, but this time by using LangChain\n",
    "- Lets connect to openai API\n",
    "- Official Tutorial for reference: https://python.langchain.com/docs/tutorials/llm_chain/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "openAIModel = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Invoke the model to get response from OpenAI using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langChainMessage = [\n",
    "    SystemMessage(\"You are a helpful assistant that answers programming questions in the style of a southern belle from the  southeast United States.\"),\n",
    "    HumanMessage(\"Are semicolons optional in JavaScript?\")\n",
    "]\n",
    "\n",
    "print(openAIModel.invoke(langChainMessage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ### Integrate LangChain with Ollama \n",
    "- Download Ollama from here: https://ollama.com/download\n",
    "- Ollama integration guide on LangChain docs: https://python.langchain.com/docs/integrations/providers/ollama/\n",
    "- Install langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain-ollama\n",
    "! ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Re-create the same application, but this time using Llama 3.2 that is running locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llamaModel = ChatOllama(model=\"llama3.2\")\n",
    "print (llamaModel.invoke(langChainMessage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Agents\n",
    "##### Demonstrate LLM's inability to fetch answers that require access to real-time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"I'm happy to help you, but I don't have real-time access to current weather conditions. However, I can suggest some options for you to find out the current weather in London:\\n\\n1. Check online weather websites: You can visit popular weather websites such as AccuWeather, BBC Weather, or The Met Office (the official UK weather service) to get the latest forecast for London.\\n2. Use a mobile app: Download a weather app on your smartphone, such as Dark Sky or Weather Underground, to get real-time weather updates for London.\\n3. Tune into local news: Watch local news channels or listen to radio stations in London to get the latest weather updates.\\n\\nIf you want, I can provide general information about the typical climate and weather patterns in London throughout the year.\" additional_kwargs={} response_metadata={'model': 'llama3.2', 'created_at': '2025-02-02T04:25:51.255237Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7846397375, 'load_duration': 47448125, 'prompt_eval_count': 37, 'prompt_eval_duration': 890000000, 'eval_count': 159, 'eval_duration': 6897000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-8bcb68ff-f9bb-4457-8558-86c87d71c072-0' usage_metadata={'input_tokens': 37, 'output_tokens': 159, 'total_tokens': 196}\n",
      "content=\"I can't provide real-time weather data. For the latest weather information in London, I recommend checking a reliable weather website or a weather app.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 23, 'total_tokens': 52, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None} id='run-417b482c-30d9-46f5-b293-e5ac986594cc-0' usage_metadata={'input_tokens': 23, 'output_tokens': 29, 'total_tokens': 52, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "getWeatherInfo = [\n",
    "    SystemMessage(\"You are a helpful assistant\"),\n",
    "    HumanMessage(\"What is the weather in London?\")\n",
    "]\n",
    "\n",
    "print(llamaModel.invoke(getWeatherInfo))\n",
    "print(openAIModel.invoke(getWeatherInfo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo of OpenWeather MAP Tool Integration\n",
    "- Install depedencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain_community pyowm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mLangChain is a framework designed for developing applications using large language models. It allows for the integration of these models with various data sources and has a focus on facilitating complex chains of interactions. \n",
      "\n",
      "Action: None needed at this moment.\n",
      "Action Input: None needed at this moment.\u001b[0m\n",
      "Observation: None needed at this moment. is not a valid tool, try one of [open_weather_map].\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to provide relevant details about LangChain without any specific actions or queries that require a tool. \n",
      "\n",
      "Final Answer: LangChain is unique because it is a framework designed for developing applications using large language models (LLMs). It provides features for integrating these models with various data sources and facilitates complex chains of interactions between different components of the application.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LangChain is unique because it is a framework designed for developing applications using large language models (LLMs). It provides features for integrating these models with various data sources and facilitates complex chains of interactions between different components of the application.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "\n",
    "tools = load_tools([\"openweathermap-api\"], openAIModel)\n",
    "\n",
    "agent_chain = initialize_agent(\n",
    "    tools=tools, llm=openAIModel, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "\n",
    "agent_chain.run(\"What is unique about LangChain?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
